
This section describes how the sound program was developed. Ut covers procedure, setup and configuration, tools and program details.



need to include a bit about the Makefile here


Description

General information about sound

Sound is a mechanical wave that is an oscillation of pressure composed of frequencies within the range of hearing.[http://en.wikipedia.org/wiki/Sound].
Humans can percieve sounds with frequencies that range from about 20Hz - the lowest of basses - to 20khz - the highest of high-pitched whining.
Sound is inherently analog, and requires some form of digital representation to be able to be generated by the ap7000.
Regarding a sound wave as a continuous signal representing wave amplitude with respect to time, one straight-forward way of representing a sound wave digitally is to simply have an list of integer signal samples at a fixed, preferrably small, time interval.
This is indeed the format the AP7000 expects for its digital-to-analog converter.

There are different strategies available for preparing the stream of integers that needs to be sent to the digital-to-analog converter to generate a sound.
One strategy is simply to store the prepared list of integers somewhere in memory, and simply copy it over to the DAC integer by integer as it consumes them over time.
This strategy is analogous to rasterized bit maps in the image world.
This strategy, while easy to implement, and is able to represent all kinds of sounds, requires a great deal of memory (integer size * sample rate of bytes per second, in fact).
On a low memory platform like the STK1000, this is therefore not a great strategy.

Another strategy is the generative approach.
This strategy is analogous to vector based images in the image world.
The idea is to generate samples at run-time based on configurations read from memory, rather than reading the pre-generated values from memory.
This is a more CPU-hungry approach, but requires less memory than the previous strategy.
This strategy is used for the sound effect synth in the presented solution program.

A third strategy is a hybrid approach, where small sample lists are pre-bundled with the program, and generative rules are used to play back the samples at different times.
This is the approach used in the music player in the presented solution program.


Development of the program

list of what we did:

* Board was set up w/ jumpers and such
* Leds and buttons were hooked up in hardware
* Leds and buttons were hooked up in software
* Code was split into separate files
* Audio was hooked up with apropriate settings
* Sound was tested to work using random noise


the following two groups of bullet points happened in parallel:

* a C sound effect synth inspired by sfxr was prototyped on a PC
* the synth was ported to avr32
* the synth was developed further on the avr32
* the synth was used in the stk1000 program to play various sound effects

* a C MOD player library + python tools inspired by amiga trackers were developed on a PC
* the library was tested on the avr32 and needed a great deal of optimization
* a great deal of optimization occurred 
* the library was used in the stk1000 program to play selected mods


finally:

* the actual main program flow was decided upon and written, hooking button and led behaviour together with sound effects and music



Configuration

We can reference our previous report here, so that we don't have to write so much.


Programming environment

JTAGICE
We can reference our previous report here, so that we don't have to write so much.

GNU Debugger
since last time:
* discovered tui mode: looks nice, breaks the makefile

Make
we can reference.

Other tools
* OpenMPT was used to examine MOD files for libmodam
* vim
* git
* github
* latex
* avr32 toolchain

Setting up the LEDs
Setting up the buttons
Setting up the audio


Program flow

* main program
* synth
* libmodam
